earth1 = earth(y~.,data=trainingData)
earth2 = earth(y~.,data=trainingData,degree=2)
earth3 = earth(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
mean((predict(earth1,validationData) - validationData$y)^2)
mean((predict(earth1,validationData) - validationData$y)^2)
mean((predict(earth2,validationData) - validationData$y)^2)
mean((predict(earth3,validationData) - validationData$y)^2)
earth4 = earth(y~.,data=trainingData,degree=2,thres=0)
earth5 = earth(y~.,data=trainingData,degree=2,thres=0.01)
earth6 = earth(y~.,data=trainingData,degree=2,thres=0.1)
mean((predict(earth4,validationData) - validationData$y)^2)
mean((predict(earth5,validationData) - validationData$y)^2)
mean((predict(earth6,validationData) - validationData$y)^2)
lm1CallRanking = order(predict(lm1,validationData),decreasing = TRUE)
earth1CallRanking = order(predict(earth1,validationData),decreasing = TRUE)
earth4CallRanking = order(predict(earth4,validationData),decreasing = TRUE)
lmcall
lm1CallRanking
nCalls = 2000
randomSuccess = round(mean(validationData$y)*nCalls)
lm1Success = sum(validationData$y[lm1CallRanking[1:nCalls]])
earth1Success = sum(validationData$y[earth1CallRanking[1:nCalls]])
earth4Success = sum(validationData$y[earth4CallRanking[1:nCalls]])
print(c(paste(randomSuccess),paste(lm1Success),paste(earth1Success),paste(earth4Success)))
library('neuralnet')
bankDataMat = model.matrix(~.,data=bankData)
install.packages("neuralnet")
library('neuralnet')
bankDataMat = model.matrix(~.,data=bankData)
colnames(bankDataMat)[3] <- "jobbluecollar"
colnames(bankDataMat)[8] <- "jobselfemployed"
View(bankDataMat)
bankDataMat = model.matrix(~.,data=bankData)
View(bankDataMat)
colnames(bankDataMat)[3] <- "jobbluecollar"
colnames(bankDataMat)[8] <- "jobselfemployed"
trainingMat = bankDataMat[isTraining,]
validationMat = bankDataMat[!isTraining,]
col_list <- paste(c(colnames(validationMat[,-c(1,44)])),collapse="+")
col_list <- paste(c("yTRUE~",col_list),collapse="")
f <- formula(col_list)
f
basicSingleLayerNNet <- neuralnet(f, data=trainingMat,
algorithm = "rprop+",
hidden=c(3),
threshold=0.1,
stepmax = 1e+06)
output <- compute(basicSingleLayerNNet, validationMat[,-c(1,44)],rep=1)
mean((validationMat[,44] - output$net.result)^2)
deepLearningNnet1 <- neuralnet(f, data=trainingMat,
algorithm = "rprop+",
hidden=c(3,3),
threshold=0.1,
stepmax = 1e+06)
nFold = 10
#Step 1: Randomly choose which fold each row is in
valNum = floor(runif(nrow(bankData))*nFold)+1
#Create a matrix where we store prediction error
modelPerformance1 = matrix(NA,nFold,length(formulaSet))
modelPerformance2 = matrix(NA,nFold,length(formulaSet))
modelPerformance3 = matrix(NA,nFold,length(formulaSet))
modelPerformance4 = matrix(NA,nFold,length(formulaSet))
for(fold in 1:nFold)
{
#Step 2i: Get the training and validation data for this fold
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
lm1 = lm(y~age+factor(month),data=trainingData)
lm2 = lm(y~poly(age,3)+factor(month),data=trainingData)
lm3 = lm(y~.,data=trainingData)
lm4 = lm(y~.^2,data=trainingData)
modelPerformance1[fold,modelNum] = mean((predict(lm1,validationData) - validationData$y)^2)
modelPerformance2[fold,modelNum] = mean((predict(lm2,validationData) - validationData$y)^2)
modelPerformance3[fold,modelNum] = mean((predict(lm3,validationData) - validationData$y)^2)
modelPerformance4[fold,modelNum] = mean((predict(lm4,validationData) - validationData$y)^2)
}
#Create a matrix where we store prediction error
modelPerformance1 = matrix(NA,nFold,4)
#modelPerformance2 = matrix(NA,nFold,length(formulaSet))
#modelPerformance3 = matrix(NA,nFold,length(formulaSet))
#modelPerformance4 = matrix(NA,nFold,length(formulaSet))
for(fold in 1:nFold)
{
#Step 2i: Get the training and validation data for this fold
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
lm1 = lm(y~age+factor(month),data=trainingData)
lm2 = lm(y~poly(age,3)+factor(month),data=trainingData)
lm3 = lm(y~.,data=trainingData)
lm4 = lm(y~.^2,data=trainingData)
modelPerformance1[fold,1] = mean((predict(lm1,validationData) - validationData$y)^2)
modelPerformance2[fold,2] = mean((predict(lm2,validationData) - validationData$y)^2)
modelPerformance3[fold,3] = mean((predict(lm3,validationData) - validationData$y)^2)
modelPerformance4[fold,4] = mean((predict(lm4,validationData) - validationData$y)^2)
}
modelPerformance = matrix(NA,nFold,4)
for(fold in 1:nFold)
{
#Step 2i: Get the training and validation data for this fold
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
lm1 = lm(y~age+factor(month),data=trainingData)
lm2 = lm(y~poly(age,3)+factor(month),data=trainingData)
lm3 = lm(y~.,data=trainingData)
lm4 = lm(y~.^2,data=trainingData)
modelPerformance[fold,1] = mean((predict(lm1,validationData) - validationData$y)^2)
modelPerformance[fold,2] = mean((predict(lm2,validationData) - validationData$y)^2)
modelPerformance[fold,3] = mean((predict(lm3,validationData) - validationData$y)^2)
modelPerformance[fold,4] = mean((predict(lm4,validationData) - validationData$y)^2)
}
colMeans(modelPerformance)
modelPerformance2 = matrix(NA,nFold,2)
for(fold in 1:nFold)
{
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
#Housing/Loan seem unimportant.  Lets delete those.
lm5 = lm(y~.^2,data=trainingData[,-c(6,7)])
modelPerformance2[fold,1] = mean((predict(lm5,validationData) - validationData$y)^2)
lm6 = lm(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
modelPerformance2[fold,2] = mean((predict(lm6,validationData) - validationData$y)^2)
}
modelPerformance = matrix(NA,nFold,4)
for(fold in 1:nFold)
{
#Step 2i: Get the training and validation data for this fold
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
lm1 = lm(y~age+factor(month),data=trainingData)
lm2 = lm(y~poly(age,3)+factor(month),data=trainingData)
lm3 = lm(y~.,data=trainingData)
lm4 = lm(y~.^2,data=trainingData)
modelPerformance[fold,1] = mean((predict(lm1,validationData) - validationData$y)^2)
modelPerformance[fold,2] = mean((predict(lm2,validationData) - validationData$y)^2)
modelPerformance[fold,3] = mean((predict(lm3,validationData) - validationData$y)^2)
modelPerformance[fold,4] = mean((predict(lm4,validationData) - validationData$y)^2)
lm5 = lm(y~.^2,data=trainingData[,-c(6,7)])
modelPerformance[fold,5] = mean((predict(lm5,validationData) - validationData$y)^2)
lm6 = lm(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
modelPerformance[fold,6] = mean((predict(lm6,validationData) - validationData$y)^2)
}
colmeans(modelPerformance)
colMeans(modelPerformance)
modelPerformance = matrix(NA,nFold,6)
for(fold in 1:nFold)
{
#Step 2i: Get the training and validation data for this fold
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
lm1 = lm(y~age+factor(month),data=trainingData)
lm2 = lm(y~poly(age,3)+factor(month),data=trainingData)
lm3 = lm(y~.,data=trainingData)
lm4 = lm(y~.^2,data=trainingData)
modelPerformance[fold,1] = mean((predict(lm1,validationData) - validationData$y)^2)
modelPerformance[fold,2] = mean((predict(lm2,validationData) - validationData$y)^2)
modelPerformance[fold,3] = mean((predict(lm3,validationData) - validationData$y)^2)
modelPerformance[fold,4] = mean((predict(lm4,validationData) - validationData$y)^2)
lm5 = lm(y~.^2,data=trainingData[,-c(6,7)])
modelPerformance[fold,5] = mean((predict(lm5,validationData) - validationData$y)^2)
lm6 = lm(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
modelPerformance[fold,6] = mean((predict(lm6,validationData) - validationData$y)^2)
}
colMeans(modelPerformance)
earthPerformance = matrix(NA,nFold,6)
for(fold in 1:nFold)
{
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
earth1 = earth(y~.,data=trainingData)
earth2 = earth(y~.,data=trainingData,degree=2)
earth3 = earth(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
earthPerformance[nFold,1] = mean((predict(earth1,validationData) - validationData$y)^2)
earthPerformance[nFold,2] = mean((predict(earth2,validationData) - validationData$y)^2)
earthPerformance[nFold,3] = mean((predict(earth3,validationData) - validationData$y)^2)
earth4 = earth(y~.,data=trainingData,degree=2,thres=0)
earth5 = earth(y~.,data=trainingData,degree=2,thres=0.01)
earth6 = earth(y~.,data=trainingData,degree=2,thres=0.1)
earthPerformance[nFold,4] = mean((predict(earth4,validationData) - validationData$y)^2)
earthPerformance[nFold,5] = mean((predict(earth5,validationData) - validationData$y)^2)
earthPerformance[nFold,6] = mean((predict(earth6,validationData) - validationData$y)^2)
}
colMeans(earthPerformance)
earthPerformance = matrix(NA,nFold,6)
for(fold in 1:nFold)
{
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
earth1 = earth(y~.,data=trainingData)
earth2 = earth(y~.,data=trainingData,degree=2)
earth3 = earth(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
earthPerformance[Fold,1] = mean((predict(earth1,validationData) - validationData$y)^2)
earthPerformance[Fold,2] = mean((predict(earth2,validationData) - validationData$y)^2)
earthPerformance[Fold,3] = mean((predict(earth3,validationData) - validationData$y)^2)
earth4 = earth(y~.,data=trainingData,degree=2,thres=0)
earth5 = earth(y~.,data=trainingData,degree=2,thres=0.01)
earth6 = earth(y~.,data=trainingData,degree=2,thres=0.1)
earthPerformance[Fold,4] = mean((predict(earth4,validationData) - validationData$y)^2)
earthPerformance[Fold,5] = mean((predict(earth5,validationData) - validationData$y)^2)
earthPerformance[Fold,6] = mean((predict(earth6,validationData) - validationData$y)^2)
}
colMeans(earthPerformance)
earthPerformance = matrix(NA,nFold,6)
for(fold in 1:nFold)
{
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
earth1 = earth(y~.,data=trainingData)
earth2 = earth(y~.,data=trainingData,degree=2)
earth3 = earth(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
earthPerformance[Fold,1] = mean((predict(earth1,validationData) - validationData$y)^2)
earthPerformance[Fold,2] = mean((predict(earth2,validationData) - validationData$y)^2)
earthPerformance[Fold,3] = mean((predict(earth3,validationData) - validationData$y)^2)
earth4 = earth(y~.,data=trainingData,degree=2,thres=0)
earth5 = earth(y~.,data=trainingData,degree=2,thres=0.01)
earth6 = earth(y~.,data=trainingData,degree=2,thres=0.1)
earthPerformance[Fold,4] = mean((predict(earth4,validationData) - validationData$y)^2)
earthPerformance[Fold,5] = mean((predict(earth5,validationData) - validationData$y)^2)
earthPerformance[Fold,6] = mean((predict(earth6,validationData) - validationData$y)^2)
}
colMeans(earthPerformance)
for(fold in 1:nFold)
{
trainingData = subset(bankData,valNum!=fold)
validationData = subset(bankData,valNum==fold)
earth1 = earth(y~.,data=trainingData)
earth2 = earth(y~.,data=trainingData,degree=2)
earth3 = earth(y~age+job+marital+education+default+contact+factor(month)+factor(day_of_week)+age*job+
age*marital+age*education+job*default+job*month+marital*month+education*month+default*
contact+default*month*contact*month+month*day_of_week,data=trainingData)
earthPerformance[fold,1] = mean((predict(earth1,validationData) - validationData$y)^2)
earthPerformance[fold,2] = mean((predict(earth2,validationData) - validationData$y)^2)
earthPerformance[fold,3] = mean((predict(earth3,validationData) - validationData$y)^2)
earth4 = earth(y~.,data=trainingData,degree=2,thres=0)
earth5 = earth(y~.,data=trainingData,degree=2,thres=0.01)
earth6 = earth(y~.,data=trainingData,degree=2,thres=0.1)
earthPerformance[fold,4] = mean((predict(earth4,validationData) - validationData$y)^2)
earthPerformance[fold,5] = mean((predict(earth5,validationData) - validationData$y)^2)
earthPerformance[fold,6] = mean((predict(earth6,validationData) - validationData$y)^2)
}
colMeans(earthPerformance)
earthPerformance = matrix(NA,nFold,6)
colMeans(modelPerformance)
lm1CallRanking = order(predict(lm1,validationData),decreasing = TRUE)
earth1CallRanking = order(predict(earth1,validationData),decreasing = TRUE)
earth4CallRanking = order(predict(earth4,validationData),decreasing = TRUE)
nCalls = 2000
randomSuccess = round(mean(validationData$y)*nCalls)
lm1Success = sum(validationData$y[lm1CallRanking[1:nCalls]])
earth1Success = sum(validationData$y[earth1CallRanking[1:nCalls]])
earth4Success = sum(validationData$y[earth4CallRanking[1:nCalls]])
print(c(paste(randomSuccess),paste(lm1Success),paste(earth1Success),paste(earth4Success)))
colMeans(earthPerformance)
set.seed(1)
isTraining = runif(nrow(bankData))<.7
trainingData = subset(bankData,isTraining)
validationData = subset(bankData,!isTraining)
randomSuccess = round(mean(validationData$y)*nCalls)
lm1Success = sum(validationData$y[lm1CallRanking[1:nCalls]])
earth1Success = sum(validationData$y[earth1CallRanking[1:nCalls]])
earth4Success = sum(validationData$y[earth4CallRanking[1:nCalls]])
print(c(paste(randomSuccess),paste(lm1Success),paste(earth1Success),paste(earth4Success)))
train = read.csv('C:/Users/Deepam Jain/Documents/GitHub/Fraud-detection-challenge/Input data/train.csv.zip')
head(train)
train = read.csv('C:/Users/Deepam Jain/Documents/GitHub/Fraud-detection-challenge/Input data/train.csv')
library(caret)
ax <-findCorrelation(x = cor(num_train), cutoff = 0.7)
rm(list=ls())
#load packages & data
library(data.table)
setwd('C:/Users/Deepam Jain/Documents/GitHub/Predicting-income-class-of-US-population/')
train <- fread("C:/Users/Deepam Jain/Documents/GitHub/Predicting-income-class-of-US-population/train/train.csv",na.strings = c(""," ","?","NA",NA))
test <- fread("C:/Users/Deepam Jain/Documents/GitHub/Predicting-income-class-of-US-population//test/test.csv",na.strings = c(""," ","?","NA",NA))
#look at data
dim(train); str (train)
dim(test); str (test)
#encode target variables
train[,income_level := ifelse(income_level == "-50000",0,1)]
test[,income_level := ifelse(income_level == "-50000",0,1)]
round(prop.table(table(train$income_level))*100)
factcols <- c(2:5,7,8:16,20:29,31:38,40,41)
numcols <- setdiff(1:40,factcols)
train[,(factcols) := lapply(.SD, factor), .SDcols = factcols]
train[,(numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
test[,(factcols) := lapply(.SD, factor), .SDcols = factcols]
test[,(numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
cat_train <- train[,factcols, with=FALSE]
cat_test <- train[,factcols, with=FALSE]
num_train <- train[,numcols,with=FALSE]
num_test <- test[,numcols,with=FALSE]
rm(train,test) #to save memory
library(ggplot2)
library(plotly)
tr <- function(a){
ggplot(data = num_train, aes(x= a, y=..density..)) + geom_histogram(fill="blue",color="red",alpha = 0.5,bins =100) + geom_density()
#ggplotly()
}
tr(num_train$age)
tr(num_train$capital_losses)
num_train[,income_level := cat_train$income_level]
ggplot(data=num_train,aes(x = age, y=wage_per_hour))+geom_point(aes(colour=income_level))+scale_y_continuous("wage per hour")#, breaks = seq(0,10000,1000))
ggplot(data=num_train,aes(x = age, y=weeks_worked_in_year))+geom_point(aes(colour=income_level))+scale_y_continuous("week worked per year")
all_bar <- function(i){
ggplot(cat_train,aes(x=i,fill=income_level))+geom_bar(position = "dodge",  color="black")+scale_fill_brewer(palette = "Pastel1")+theme(axis.text.x =element_text(angle  = 60,hjust = 1,size=10))
}
all_bar(cat_train$class_of_worker)
all_bar(cat_train$education)
prop.table(table(cat_train$marital_status,cat_train$income_level),1)
prop.table(table(cat_train$class_of_worker,cat_train$income_level),1)
table(is.na(num_train))
table(is.na(num_test))
library(caret)
ax <-findCorrelation(x = cor(num_train), cutoff = 0.7)
table(is.na(num_train))
table(is.na(num_test))
is.na(num_train)
table(is.na(num_train))
table(is.na(num_test))
library(caret)
library(ggplot2)
install.packages('Rcpp')
library(ggplot2)
install.packages('rlang')
library(ggplot2)
library(plotly)
library(caret)
ax <-findCorrelation(x = cor(num_train), cutoff = 0.7)
rm(list=ls())
#load packages & data
library(data.table)
setwd('C:/Users/Deepam Jain/Documents/GitHub/Predicting-income-class-of-US-population/')
train <- fread("C:/Users/Deepam Jain/Documents/GitHub/Predicting-income-class-of-US-population/train/train.csv",na.strings = c(""," ","?","NA",NA))
test <- fread("C:/Users/Deepam Jain/Documents/GitHub/Predicting-income-class-of-US-population//test/test.csv",na.strings = c(""," ","?","NA",NA))
#look at data
dim(train); str (train)
dim(test); str (test)
#encode target variables
train[,income_level := ifelse(income_level == "-50000",0,1)]
test[,income_level := ifelse(income_level == "-50000",0,1)]
round(prop.table(table(train$income_level))*100)
factcols <- c(2:5,7,8:16,20:29,31:38,40,41)
numcols <- setdiff(1:40,factcols)
train[,(factcols) := lapply(.SD, factor), .SDcols = factcols]
train[,(numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
test[,(factcols) := lapply(.SD, factor), .SDcols = factcols]
test[,(numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
cat_train <- train[,factcols, with=FALSE]
cat_test <- train[,factcols, with=FALSE]
num_train <- train[,numcols,with=FALSE]
num_test <- test[,numcols,with=FALSE]
rm(train,test) #to save memory
library(ggplot2)
library(plotly)
tr <- function(a){
ggplot(data = num_train, aes(x= a, y=..density..)) + geom_histogram(fill="blue",color="red",alpha = 0.5,bins =100) + geom_density()
#ggplotly()
}
tr(num_train$age)
tr(num_train$capital_losses)
num_train[,income_level := cat_train$income_level]
ggplot(data=num_train,aes(x = age, y=wage_per_hour))+geom_point(aes(colour=income_level))+scale_y_continuous("wage per hour")#, breaks = seq(0,10000,1000))
ggplot(data=num_train,aes(x = age, y=weeks_worked_in_year))+geom_point(aes(colour=income_level))+scale_y_continuous("week worked per year")
all_bar <- function(i){
ggplot(cat_train,aes(x=i,fill=income_level))+geom_bar(position = "dodge",  color="black")+scale_fill_brewer(palette = "Pastel1")+theme(axis.text.x =element_text(angle  = 60,hjust = 1,size=10))
}
all_bar(cat_train$class_of_worker)
all_bar(cat_train$education)
prop.table(table(cat_train$marital_status,cat_train$income_level),1)
prop.table(table(cat_train$class_of_worker,cat_train$income_level),1)
table(is.na(num_train))
table(is.na(num_test))
library(caret)
ax <-findCorrelation(x = cor(num_train), cutoff = 0.7)
View(num_test)
View(num_train)
cor(num_train)
corr(num_train)
sapply(num_train,class)
cor(num_train[,-1])
num_train[,-1]
num_train[1:7]
num_train[,1:7]
cor(num_train[,1:7])
num_train$income_level <- as.numeric(num_train$income_level)
ax <-findCorrelation(x = cor(num_train), cutoff = 0.7)
head(ax)
ax
num_train <- num_train[,-ax,with=FALSE]
num_test[,weeks_worked_in_year := NULL]
num_test[,weeks_worked_in_year := NULL]
View(num_test)
#check missing values per columns
mvtr <- sapply(cat_train, function(x){sum(is.na(x))/length(x)})*100
mvte <- sapply(cat_test, function(x){sum(is.na(x)/length(x))}*100)
mvte
cat_train <- subset(cat_train,select = mvtr < 5)
cat_test <- subset(cat_test,select = mvte < 5)
#set NA as Unavailable - train data
#convert to characters
cat_train <- cat_train[,names(cat_train) := lapply(.SD, as.character),.SDcols = names(cat_train)]
for (i in seq_along(cat_train)) set(cat_train, i=which(is.na(cat_train[[i]])), j=i, value="Unavailable")
#convert back to factors
cat_train <- cat_train[, names(cat_train) := lapply(.SD,factor), .SDcols = names(cat_train)]
#set NA as Unavailable - test data
cat_test <- cat_test[, (names(cat_test)) := lapply(.SD, as.character), .SDcols = names(cat_test)]
for (i in seq_along(cat_test)) set(cat_test, i=which(is.na(cat_test[[i]])), j=i, value="Unavailable")
#convert back to factors
cat_test <- cat_test[, (names(cat_test)) := lapply(.SD, factor), .SDcols = names(cat_test)]
#combine factor levels with less than 5% values
#train
for(i in names(cat_train)){
p <- 5/100
ld <- names(which(prop.table(table(cat_train[[i]])) < p))
levels(cat_train[[i]])[levels(cat_train[[i]]) %in% ld] <- "Other"
}
sapply(cat_train,class)
#test
for(i in names(cat_test)){
p <- 5/100
ld <- names(which(prop.table(table(cat_test[[i]])) < p))
levels(cat_test[[i]])[levels(cat_test[[i]]) %in% ld] <- "Other"
}
library(mlr)
install.packages('mlr')
library(mlr)
summarizeColumns(cat_train)[,"nlevs"]
summarizeColumns(cat_test)[,"nlevs"]
summarizeColumns(cat_train)
num_train[,.N,age][order(age)]
num_train[,.N,age]
num_train[,.N,age]
num_train[,.N,age][order(age)]
num_train[,.N,wage_per_hour][order(-N)]
#bin age variable 0-30 31-60 61 - 90
num_train[,age:= cut(x = age,breaks = c(0,30,60,90),include.lowest = TRUE,labels = c("young","adult","old"))]
num_train[,age := factor(age)]
View(num_train)
dim(num_train)
str(num_train)
sapply(num_train,class)
num_test[,age:= cut(x = age,breaks = c(0,30,60,90),include.lowest = TRUE,labels = c("young","adult","old"))]
num_test[,age := factor(age)]
num_train[,wage_per_hour := ifelse(wage_per_hour == 0,"Zero","MoreThanZero")][,wage_per_hour := as.factor(wage_per_hour)]
num_train[,capital_gains := ifelse(capital_gains == 0,"Zero","MoreThanZero")][,capital_gains := as.factor(capital_gains)]
num_train[,capital_losses := ifelse(capital_losses == 0,"Zero","MoreThanZero")][,capital_losses := as.factor(capital_losses)]
num_train[,dividend_from_Stocks := ifelse(dividend_from_Stocks == 0,"Zero","MoreThanZero")][,dividend_from_Stocks := as.factor(dividend_from_Stocks)]
num_test[,wage_per_hour := ifelse(wage_per_hour == 0,"Zero","MoreThanZero")][,wage_per_hour := as.factor(wage_per_hour)]
num_test[,capital_gains := ifelse(capital_gains == 0,"Zero","MoreThanZero")][,capital_gains := as.factor(capital_gains)]
num_test[,capital_losses := ifelse(capital_losses == 0,"Zero","MoreThanZero")][,capital_losses := as.factor(capital_losses)]
num_test[,dividend_from_Stocks := ifelse(dividend_from_Stocks == 0,"Zero","MoreThanZero")][,dividend_from_Stocks := as.factor(dividend_from_Stocks)]
num_train[,income_level := NULL]
#combine data and make test & train files
d_train <- cbind(num_train,cat_train)
d_test <- cbind(num_test,cat_test)
#remove unwanted files
rm(num_train,num_test,cat_train,cat_test) #save memory
#create task
train.task <- makeClassifTask(data = d_train,target = "income_level")
test.task <- makeClassifTask(data=d_test,target = "income_level")
?makeClassifTask
#remove zero variance features
train.task <- removeConstantFeatures(train.task)
test.task <- removeConstantFeatures(test.task)
#create task
train.task <- makeClassifTask(data = d_train,target = "income_level")
type(d_train)
typeof(d_train)
d_train <- as.data.frame(d_train)
typeof(d_train)
#create task
train.task <- makeClassifTask(data = d_train,target = "income_level")
d_test <- as.data.frame(d_test)
#create task
train.task <- makeClassifTask(data = d_train,target = "income_level")
test.task <- makeClassifTask(data= d_test,target = "income_level")
View(d_test)
#remove zero variance features
train.task <- removeConstantFeatures(train.task)
test.task <- removeConstantFeatures(test.task)
#get variable importance chart
var_imp <- generateFilterValuesData(train.task, method = c("information.gain"))
install.packages('FSelector')
library(FSelector)
#get variable importance chart
var_imp <- generateFilterValuesData(train.task, method = c("information.gain"))
library(ggplot2)
library(plotly)
library(caret)
library(mlr)
#get variable importance chart
var_imp <- generateFilterValuesData(train.task, method = c("information.gain"))
install.packages('rJava')
library(FSelector)
library(rJava)
library(FSelector)
library(FSelector)
library(mlr)
#get variable importance chart
var_imp <- generateFilterValuesData(train.task, method = c("information.gain"))
